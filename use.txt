conda activate dzlnev
salloc --nodes=1 --job-name=Aug --gres=gpu:8 --cpus-per-task=52 --cpus-per-gpu=2 --partition=gpu

salloc --nodes=1 --job-name=Aug_T --gres=gpu:4 --cpus-per-task=30 --cpus-per-gpu=2 --partition=gpu


# apply gpu source
salloc --nodes=1 --job-name=acapp --gres=gpu:1   --partition=gpu
#  login oon gpu
ssh gpu(x)

# gpu info 
nvidia-smi

conda activate seg
sbatch -s job.sh
# 1. 如“sbatch -s pfn.sh”，pfn.sh和main.py位于同一目录
#     1. #!/bin/bash
#     2. #SBATCH --gres=gpu:1
#     3. python main.py

# 查看job
squeue

# 取消资源 +JOBID
scancel




# 可持久化记录输出
python run.py --model bert --test yes > test.log 2>&1
python run.py --model bert --test no > >(tee -a test256.log) 2>&1

# scp
scp -P 20000  use.txt  acs@124.223.72.23:/home/acs


# 单个服务打包：根据当前的Dockerfile构建一个docker镜像
docker build -t emr_similarity_image .

# 根据docker compose启动docker容器
docker-compose up

# 生成最小requirement.txt
pipreqs . --force --encoding=utf-8

# 运行dvc 队列中的实验  --jobs 2 表示运行前2个
dvc exp run --run-all --jobs 2 

# 根据实验name来运行
dvc exp run --run-all --jobs 1 --name  <experiment_id>


# 将处于失败状态的实验重新添加到实验队列
dvc exp remove ..
dvc exp run --queue

# 管道中的输出文件自动加入.gitignore  同时管道repro会生成一个dvc.lock,会记录这些中间文件的md5信息，在dvc push时会加入到远程仓库



